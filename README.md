This project takes audio input files, converts them to a CSV off FFT data, and reads the file into a processing project to generate graphic musical notation.
Start by using the python notebook with librosa. Upload an audio file and run the functions that follow. The get dims function outputs scaled proportions.
The output (scaled to a 16 / 9 aspect ratio), is the source width and height for the processing sketch. This needs to be updated manually. Processing will automatically save the image when finished. It is recommended to run the python as a colab notebook.
This keeps the envirnment managment simple.

Expected run times. 
1-3 Minute Track: <5 mins <br/>
3-7 Minute Track: 5 - 15 mins<br/>
7+ Minute Track: 20+ minutes


Goal: 
The goal of this project is to provide a new means of generating graphic musical notation. There are currently no tools which I find satisfactory for doing so. 
This has applications for composers, educators, and artists. The project is heavily inspired by Xenakis and Cornelius Cardew's "Treatise".

Future Updates:
I plan to rebuild the tool only using Python in the future. I plan to make it available as an open source tool.
I hope that I can integrate the analysis and generation into one tool 
The tool is currently limited in terms of styles, color palletes, resolution, and density.
I plan to update this.

Test Material Linked in the google drive folder (about section). Includes test CSV set and resulting images. Audio is from Lucian Parisi's "Riparian Forms" album. <br/>
https://open.spotify.com/album/3llCYRRL5SXWuLAwUtUwX0?si=8yU5HaTKRHuEn1HjwEe2NQ
